{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "!!! VERY IMPORTANT INFORMATION AFTER RELEASE OF TENSORFLOW 2.8.0 !!!\n",
    "\n",
    "It seems that colab uses an old version of cuDNN on board. This is a problem\n",
    "because all of our code (with packages) are \"compiled\" on another version.\n",
    "Because of this\n",
    "\n",
    "To still be able to run everything on this notebook, please do the following steps:\n",
    "\n",
    "* Register an Nvidia Developer account (https://developer.nvidia.com/)\n",
    "* Go to https://developer.nvidia.com/rdp/cudnn-archive\n",
    "* Go to \"Download cuDNN v8.1.0 (January 26th, 2021), for CUDA 11.0,11.1 and 11.2\"\n",
    "* Find and download \"cuDNN Runtime Library for Ubuntu18.04 x86_64 (Deb)\"\n",
    "* Put the downloaded file to the root directory of this colab machine"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#uncomment this and run this if necessary\n",
    "# !dpkg -i \"libcudnn8_8.1.0.77-1+cuda11.2_amd64.deb\"\n",
    "# !pip install OpenNMT-tf"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As of 01.02.2022 everything should work fine after this"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 0 Information\n",
    "\n",
    "## 0.1 Prerequisites\n",
    "\n",
    "### 0.1.1 Git\n",
    "* Should be installed\n",
    "* Should be available via path, so that it is possible to call `git clone ...` directly from the console\n",
    "\n",
    "### 0.1.2 `tar` tool\n",
    "TODO\n",
    "\n",
    "### 0.1.3 Python\n",
    "It is recommended to use version 3.8+. The oldest version on which\n",
    "this notebook and all codebase scripts have been tested is 3.7.\n",
    "\n",
    "## 0.2 Recommendations\n",
    "\n",
    "### 0.2.1 Configuration\n",
    "The current setup of this file allow you to completely run all the modules of the project without any problems.\n",
    "If you wish to simply execute all the functions, and you don't require special configuration or output directories\n",
    "then please stick to the configuration that is provided here by default.\n",
    "\n",
    "### 0.2.2 Virtual environment\n",
    "It is recommended to run this notebook in a separate python virtual environment.\n",
    "`conda`, `venv` or any other virtual environment creation options are suitable for this.\n",
    "Even though this is not a requirement to run this notebook it is very\n",
    "recommended using a virtual environment\n",
    "\n",
    "Here is a small tutorial on how to set a virtual environment with `venv`:\n",
    "\n",
    "TODO"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1 Setup"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.1 Config"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.1.1 `CLONE_GITHUB_REPO`\n",
    "Set to true if you only have the notebook\n",
    "and you don't have the other parts of codebase.\n",
    "This option will allow the notebook to pull\n",
    "all the codebase form the github repo of this project"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "CLONE_GITHUB_REPO = True"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.1.2 `MAIN_PACKAGE_PATH`\n",
    "This is the path to the codebase directory, where all the subpackages and modules are stored.\n",
    "If `CLONE_GITHUB_REPO` is `True` then this will be interpreted as the path to which the GitHub\n",
    "Repo will be cloned. This path can be provided as an absolute path or as a relative path\n",
    "to the file of this notebook.\n",
    "\n",
    "*   If you run this notebook \"out of the box\" i.e. with the GitHub repo already cloned,\n",
    "    please specify `MAIN_PACKAGE_PATH = '.'`\n",
    "    *   When is this applicable: this file's path is `repo_root/main.ipynb` where `repo_root`\n",
    "        is the path to the cloned GitHub repo of this project with the whole codebase\n",
    "*   If this notebook is not in the context of the cloned GitHub repo of this project then\n",
    "    please specify your custom path. IMPORTANT: the final directory, in which the repo will be cloned\n",
    "    **should always have the name`studienprojekt_cv_rvv`**\n",
    "    * Allowed paths (unix-like, windows are analogous):\n",
    "        * `/home/user/Desktop/studienprojekt_cv_rvv`\n",
    "        * `./studienprojekt_cv_rvv`\n",
    "        * `./another/example/directory/studienprojekt_cv_rvv`\n",
    "        * `.` on condition that the current working directory has name `studienprojekt_cv_rvv`\n",
    "        * `..` on condition that the parent directory of the current working directory is `studienprojekt_cv_rvv`\n",
    "        * `../../just/another/example/studienprojekt_cv_rvv`\n",
    "    * Disallowed paths (unix-like, windows are analogous):\n",
    "        * `/home/user/Desktop/studienprojekt`\n",
    "        * `./project`\n",
    "        * `./another/example/directory`\n",
    "        * `.` on condition that the current working directory **does not have** name `studienprojekt_cv_rvv`\n",
    "        * `..` on condition that the parent directory of the current working directory **is not** `studienprojekt_cv_rvv`\n",
    "        * `../../just/another/example`"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "MAIN_PACKAGE_PATH = './studienprojekt_cv_rvv' if CLONE_GITHUB_REPO else '.'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.1.3 `SCRIPTS_EXEC_MODE`\n",
    "It is possible to execute all scripts in `verbose` mode to display\n",
    "all logs that are displayed by the scripts themselves\n",
    "and also by all the subprocesses that they start. However, if you use `silent` mode\n",
    "then no logs will be displayed. Only important messages like errors and\n",
    "important execution checkpoints will be logged in silent mode."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "SCRIPTS_EXEC_MODE = 'verbose'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.1.4 `EVAL_SPLIT_RATIO`\n",
    "Specify a float value from `0.0` to `1.0` which defines how big the part of images should\n",
    "be used for evaluation. Value of `0.2` means that 20% of all the images in the provided dataset\n",
    "should be used for evaluation. The rest is used for training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "EVAL_SPLIT_RATIO = 0.2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.1.5 `NUM_TRAIN_STEPS`\n",
    "The number of training steps during the model training process. A training step is ...TODO..."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "NUM_TRAIN_STEPS = 1000"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.2 Definitions of constants\n",
    "*Note: You still have to run these cells for further cells to function correctly.\n",
    "But please only edit this part of the notebook if you know what you are doing*"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "GITHUB_REPO_LINK = 'https://github.com/Maks0bs/study-project-cv-real-vs-virtual.git'\n",
    "CHECKPOINT_EVERY_N = 100"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.3 Imports\n",
    "Here all external packages are imported"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2 Workspace preparation\n",
    "All of these cells should be run only for one time when we \"start from scratch\" with this notebook\n",
    "\n",
    "## 2.1 Codebase\n",
    "Pull the codebase from GitHub if necessary and verify its installation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if CLONE_GITHUB_REPO:\n",
    "    !git clone {GITHUB_REPO_LINK} {MAIN_PACKAGE_PATH}\n",
    "\n",
    "# TODO: verify codebase installation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.2 Package setup\n",
    "Install the project package to the python (virtual) environment"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "main_package_parent = os.path.dirname(MAIN_PACKAGE_PATH)\n",
    "shutil.copy(\n",
    "    os.path.join(MAIN_PACKAGE_PATH, 'setup.py'),\n",
    "    main_package_parent\n",
    ")\n",
    "!pip install -e {main_package_parent}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3 TFOD API and pretrained model\n",
    "Here we install Tensorflow Object Detection API and\n",
    "load the pretrained model that is specified in the config.\n",
    "Generally, the TFOD API should only be installed once.\n",
    "However, several pretrained models can be loaded (when the config is changed)\n",
    "and in this case it is required to run these cells once again\n",
    "for the new pretrained model to be used during training."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!python {os.path.join(MAIN_PACKAGE_PATH, 'setup', 'workspace.py')} -m {SCRIPTS_EXEC_MODE} -v \"both\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4 Dataset preparation\n",
    "Here we create the processed dataset with splitting into train and test sets.\n",
    "Please put your raw perception data in ./studienprojekt_cv_rvv/data/datasets/raw/my_dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!python {os.path.join(MAIN_PACKAGE_PATH, 'data', 'preparation.py')} -m {SCRIPTS_EXEC_MODE} -sr {EVAL_SPLIT_RATIO}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5 Train the model\n",
    "Train the model on the created TF records"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!python {os.path.join(MAIN_PACKAGE_PATH, 'train', 'train.py')} -m {SCRIPTS_EXEC_MODE} --num_train_steps {NUM_TRAIN_STEPS} --checkpoint_every_n {CHECKPOINT_EVERY_N}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6 Evaluate the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "command = \"python {} --model_dir={} --pipeline_config_path={} --checkpoint_dir={}\".format('/content/studienprojekt_cv_rvv/tfod_api/object_detection/model_main_tf2.py', '/content/studienprojekt_cv_rvv/models/trained/my_model' ,'/content/studienprojekt_cv_rvv/models/trained/my_model/pipeline.config', '/content/studienprojekt_cv_rvv/models/trained/my_model')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(command)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!{command}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 7 Image Object Detection"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "from object_detection.utils import config_util"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Image Object Detection\n",
    "\n",
    "PIPELINE_CONFIG_FILE = ''\n",
    "LABELMAP_FILE = ''\n",
    "NEW_CKPT_PATH = ''\n",
    "\n",
    "configs = config_util.get_configs_from_pipeline_file(PIPELINE_CONFIG_FILE)\n",
    "detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n",
    "\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore(os.path.join(NEW_CKPT_PATH, 'ckpt-XXX')).expect_partial()\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def detect_fn(image):\n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "    return detections"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "category_index = label_map_util.create_category_index_from_labelmap(LABELMAP_FILE)\n",
    "IMAGE_PATH = ''"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "img = cv2.imread(IMAGE_PATH)\n",
    "image_np = np.array(img)\n",
    "\n",
    "input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "detections = detect_fn(input_tensor)\n",
    "\n",
    "num_detections = int(detections.pop('num_detections'))\n",
    "detections = {key: value[0, :num_detections].numpy()\n",
    "              for key, value in detections.items()}\n",
    "detections['num_detections'] = num_detections\n",
    "\n",
    "# detection_classes should be ints.\n",
    "detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "label_id_offset = 1\n",
    "image_np_with_detections = image_np.copy()\n",
    "\n",
    "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "            image_np_with_detections,\n",
    "            detections['detection_boxes'],\n",
    "            detections['detection_classes']+label_id_offset,\n",
    "            detections['detection_scores'],\n",
    "            category_index,\n",
    "            use_normalized_coordinates=True,\n",
    "            max_boxes_to_draw=10,\n",
    "            min_score_thresh=.25,\n",
    "            agnostic_mode=False)\n",
    "\n",
    "plt.imshow(cv2.cvtColor(image_np_with_detections, cv2.COLOR_BGR2RGB))\n",
    "plt.savefig('test.png')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "tf2_studienprojekt",
   "language": "python",
   "display_name": "tf2_studienprojekt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}